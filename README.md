В рамках этой задачи мы стремимся научить нашу нейронную сеть распознавать поддельные новости.

# 1. Установка необходимых библиотек

Первым шагом нам необходимо установить следующие библиотеки:

   – **pip install numpy**  
   – **pip install pandas**  
   – **pip install scikit-learn**  
   – **pip install matplotlib**  

  **pip install numpy** — эта библиотека понадобится нам для сортировки признаков (весов модели) в одном из фрагментов кода.

  **pip install pandas** — эта библиотека необходима для чтения CSV-файла и его преобразования в DataFrame.

  **pip install scikit-learn** — это ключевая библиотека, которая поможет нам преобразовать текст в числа и обучить нашу модель.

  **pip install matplotlib** — эта библиотека потребуется для визуализации полученных результатов.

После успешной установки всех необходимых библиотек мы можем импортировать их в наш проект:

 ![image](https://github.com/user-attachments/assets/b2155dd7-6c86-404f-906b-a9e5e3588eb5)

Команда **as** (import pandas as pd) служит для удобного переименования нашей библиотеки в соответствии с нашими предпочтениями.

# 2. Начало работы

Прежде всего, давайте извлечем наши данные из CSV-файла с помощью библиотеки pandas:

 ![image](https://github.com/user-attachments/assets/6a641997-0f40-4226-b67c-df02675c225d)

Теперь давайте посмотрим на структуру наших данных с помощью метода **head**, который выводит первые пять записей:

 ![image](https://github.com/user-attachments/assets/4a68e756-8007-49c0-b293-b2ff0d459f15)

Вывод:

 ![image](https://github.com/user-attachments/assets/1b48087c-7e0c-46fb-9291-b4406501d60c)

Чтобы просмотреть данные в столбцах, выполните следующие действия:

 ![image](https://github.com/user-attachments/assets/6b492880-5b83-4f25-b0f7-3575f08d4a63)

Вывод:

 ![image](https://github.com/user-attachments/assets/8f4d68be-4e94-40d5-a607-848a3b467cba)

 ![image](https://github.com/user-attachments/assets/9bb23cd5-9142-4579-ab89-95c208b6fd75)

Для обучения нам потребуются текст новости и метка, указывающая на ее подлинность (FAKE/REAL). Эта метка будет служить правильным ответом, который мы будем использовать для обучения и проверки нашей модели. Такой метод называется обучением с учителем, поскольку данные уже размечены.

Извлечем текст новости (text) и метку (label) из нашего фрейма данных:

 ![image](https://github.com/user-attachments/assets/950decb4-6717-425f-92c3-c99df7fc3c16)

Затем нам необходимо разделить данные на две части: тренировочные и тестовые. На тренировочных данных мы будем обучать модель, а на тестовых — проверять ее навыки.

 ![image](https://github.com/user-attachments/assets/0b5d6909-a9b1-4b90-8e58-0202963a2695)

Здесь X_train, X_test, y_train и y_test представляют собой разделение данных и их меток.

**test_size=0.2** — этот параметр определяет размер тестовых данных, который составляет 20%, как и в нашем случае.

**random_state=33** — этот параметр служит для перемешивания данных. Вы можете указать любое число, но лучше выбрать что-то уникальное.

Теперь настроим наш TfidfVectorizer:

 ![image](https://github.com/user-attachments/assets/3d89d2b5-87ac-427f-aa2d-7e1a2dd49356)

**stop_words = 'english'** — задаем язык и указываем, что нужно исключить слова, не имеющие большой смысловой нагрузки, такие как «the», «and», «is».

**max_df = 0.7** — исключаем слова, которые встречаются более чем в 70% статей, так как они, вероятно, не являются полезными.

Преобразуем наши текстовые данные в векторы признаков (веса), где каждое слово будет иметь свой признак. Это необходимо, поскольку нейронная сеть обучается только на числовых данных. Чтобы облегчить ей задачу, мы преобразуем эти данные в векторное представление.

 ![image](https://github.com/user-attachments/assets/b19141da-ded1-498e-8dd7-a4146f38b08d)

Наконец, создадим модель для обучения PassiveAggressiveClassifier.

PassiveAggressiveClassifier — это модель, которая использует два типа поведения: пассивный и агрессивный.

* **Пассивный режим**: если модель правильно предсказывает результат, она не предпринимает никаких действий.

* **Агрессивный режим**: в случае ошибки модель активно меняет свои веса, интенсивность этих изменений зависит от величины ошибки.

Здесь мы обучаем модель, и она пытается предсказать результат, подбирая оптимальные веса.

 ![image](https://github.com/user-attachments/assets/0fe18773-fe65-4c08-bf98-f56c451e62b8)

Запишем результаты предсказаний модели, сделанные на тестовых данных:

 ![image](https://github.com/user-attachments/assets/9666deaa-7f1e-4c5d-90ed-b5b5011a6d93)

Вычислим точность модели:

 ![image](https://github.com/user-attachments/assets/3a67899e-41cf-4d43-b7ab-c81c51a8ee63)

 ![image](https://github.com/user-attachments/assets/144b80fe-28e1-4fbb-a026-b41101631720)

Визуализируем матрицу ошибок:

 ![image](https://github.com/user-attachments/assets/749f3f77-009d-430a-ab25-8248f2d0e413)

Посмотрим, где накосячила модель:

 ![image](https://github.com/user-attachments/assets/b9e96156-6488-412e-abf4-9b7d4826bc50)

Теперь нарисуем 10 слов с наибольшим вкладом в модель:

 ![image](https://github.com/user-attachments/assets/bf078852-b24b-4a00-891b-9132c60c3282)

Получим для этих слов признаки (веса):

 ![image](https://github.com/user-attachments/assets/7103e6e0-06f6-450c-9fd7-afbfcb336d1b)

Чтобы получить первый элемент, мы используем индекс [0]. Это связано с тем, что признаки хранятся в виде двумерного массива, который выглядит как [[1, 2, 3, 4]]. Поэтому мы обращаемся к [0]-му элементу, который и содержит наши признаки.

Далее сортируем признаки по возрастанию и берём последние 10 индексов. Зададим размер графика:

 ![image](https://github.com/user-attachments/assets/c511102d-2474-493e-b3ad-7d288d12b11d)

Мы выводим каждое слово в цикле и получаем для него значение признака в конце рисуем график:

![image](https://github.com/user-attachments/assets/4ae0d7c4-561a-4284-bb7a-37ae5459c6fc)

![image](https://github.com/user-attachments/assets/47c2ed90-2792-480f-98f9-8b22f008da38)


